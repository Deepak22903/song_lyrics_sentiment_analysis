{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genius Lyrics Sentiment Analysis\n",
    "\n",
    "## Project Overview\n",
    "Sentiment analysis and preprocessing of the Genius Lyrics dataset using a lexicon-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')        # Original tokenizer\n",
    "nltk.download('punkt_tab')    # New Punkt sentence tokenizer data (required for newer NLTK versions)\n",
    "nltk.download('stopwords')    # Stopwords\n",
    "nltk.download('wordnet')      # WordNet lemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Initial Exploration Function\n",
    "def load_and_explore_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Load Genius Lyrics dataset and perform initial exploration with 1000 rows limit\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : str\n",
    "        Path to the CSV file containing lyrics\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Loaded and preprocessed dataset limited to 1000 rows\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset and limit to 1000 rows\n",
    "        # df = pd.read_csv(file_path, encoding='utf-8').sample(n=1000, random_state=42)\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "        \n",
    "        # Basic dataset information\n",
    "        print(\"Dataset Information:\")\n",
    "        print(f\"Total number of entries (limited): {len(df)}\")\n",
    "        \n",
    "        # Language distribution\n",
    "        print(\"\\nLanguage Distribution:\")\n",
    "        print(df['language'].value_counts())\n",
    "        \n",
    "        # Genre distribution\n",
    "        print(\"\\nGenre Distribution:\")\n",
    "        print(df['tag'].value_counts().head())\n",
    "        \n",
    "        # Filter for English lyrics\n",
    "        df_english = df[df['language'] == 'en'].copy()\n",
    "        print(f\"\\nNumber of English lyrics: {len(df_english)}\")\n",
    "        \n",
    "        return df_english\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing Functions\n",
    "def clean_lyrics(text):\n",
    "    \"\"\"\n",
    "    Comprehensive text cleaning for lyrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input lyrics text\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Cleaned lyrics\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove brackets and content inside them (often used for song section labels)\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove special characters and extra whitespaces\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove English stopwords from text\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input text\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Text with stopwords removed\n",
    "    \"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Preprocessing and Analysis Functions\n",
    "def preprocess_lyrics_dataset(df):\n",
    "    \"\"\"\n",
    "    Apply comprehensive preprocessing to lyrics dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe with lyrics\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Preprocessed dataframe\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Clean lyrics\n",
    "    processed_df['cleaned_lyrics'] = processed_df['lyrics'].apply(clean_lyrics)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    processed_df['processed_lyrics'] = processed_df['cleaned_lyrics'].apply(remove_stopwords)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "def analyze_lyrics_sentiment(text):\n",
    "    \"\"\"\n",
    "    Determine sentiment using TextBlob\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    text : str\n",
    "        Input lyrics text\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Sentiment analysis results\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    # Sentiment polarity\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    \n",
    "    # Categorize sentiment\n",
    "    if polarity > 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif polarity < -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment,\n",
    "        'polarity': polarity,\n",
    "        'subjectivity': subjectivity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "def visualize_sentiment_distribution(df):\n",
    "    \"\"\"\n",
    "    Create visualizations for sentiment distribution\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Preprocessed dataframe with sentiment analysis\n",
    "    \"\"\"\n",
    "    # Sentiment Distribution Pie Chart\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sentiment_counts = df['sentiment'].value_counts()\n",
    "    plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Sentiment Distribution')\n",
    "    \n",
    "    # Sentiment Distribution by Genre\n",
    "    plt.subplot(1, 2, 2)\n",
    "    genre_sentiment = df.groupby('tag')['sentiment'].value_counts(normalize=True).unstack()\n",
    "    genre_sentiment.plot(kind='bar', stacked=True)\n",
    "    plt.title('Sentiment Distribution by Genre')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_sentiment_by_features(df):\n",
    "    \"\"\"\n",
    "    Analyze sentiment across different features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Preprocessed dataframe\n",
    "    \"\"\"\n",
    "    # Sentiment by Year\n",
    "    yearly_sentiment = df.groupby('year')['sentiment'].value_counts(normalize=True).unstack()\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    yearly_sentiment.plot(kind='line', marker='o')\n",
    "    plt.title('Sentiment Trends Over Years')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Top Artists by Sentiment\n",
    "    plt.subplot(1, 2, 2)\n",
    "    top_artists = df['artist'].value_counts().head(10).index\n",
    "    artist_sentiment = df[df['artist'].isin(top_artists)].groupby('artist')['sentiment'].value_counts(normalize=True).unstack()\n",
    "    artist_sentiment.plot(kind='bar', stacked=True)\n",
    "    plt.title('Sentiment Distribution for Top Artists')\n",
    "    plt.xlabel('Artist')\n",
    "    plt.ylabel('Proportion')\n",
    "    plt.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "Total number of entries (limited): 5134856\n",
      "\n",
      "Language Distribution:\n",
      "language\n",
      "en    3374198\n",
      "es     275432\n",
      "fr     189436\n",
      "pt     167947\n",
      "ru     166044\n",
      "       ...   \n",
      "mt          5\n",
      "uz          4\n",
      "tg          3\n",
      "bs          1\n",
      "gu          1\n",
      "Name: count, Length: 84, dtype: int64\n",
      "\n",
      "Genre Distribution:\n",
      "tag\n",
      "pop     2138587\n",
      "rap     1724816\n",
      "rock     793220\n",
      "rb       196462\n",
      "misc     181455\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of English lyrics: 3374198\n"
     ]
    }
   ],
   "source": [
    "# Main Execution Function\n",
    "def main(file_path):\n",
    "    # Step 1: Load and Explore Dataset\n",
    "    df_english = load_and_explore_dataset(file_path)\n",
    "    \n",
    "    if df_english is not None:\n",
    "        # Step 2: Preprocess Lyrics\n",
    "        processed_df = preprocess_lyrics_dataset(df_english)\n",
    "        \n",
    "        # Step 3: Perform Sentiment Analysis\n",
    "        sentiment_results = processed_df['processed_lyrics'].apply(analyze_lyrics_sentiment)\n",
    "        processed_df['sentiment'] = sentiment_results.apply(lambda x: x['sentiment'])\n",
    "        processed_df['polarity'] = sentiment_results.apply(lambda x: x['polarity'])\n",
    "        processed_df['subjectivity'] = sentiment_results.apply(lambda x: x['subjectivity'])\n",
    "        \n",
    "        # Step 4: Visualize Results\n",
    "        visualize_sentiment_distribution(processed_df)\n",
    "        analyze_sentiment_by_features(processed_df)\n",
    "        \n",
    "        # Optional: Save processed dataset\n",
    "        processed_df.to_csv('processed_genius_lyrics_dataset.csv', index=False)\n",
    "        \n",
    "        return processed_df\n",
    "\n",
    "# Usage\n",
    "if __name__ == '__main__':\n",
    "    # Replace with the actual path to your Genius Lyrics dataset\n",
    "    file_path = '/home/deepak/dsciProject/new/song_lyrics.csv'\n",
    "    processed_data = main(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
