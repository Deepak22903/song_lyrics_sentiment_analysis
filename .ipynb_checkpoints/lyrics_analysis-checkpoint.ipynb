{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/deepak/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error tokenizing data. C error: EOF inside string starting at row 2667951\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Explore Dataset\n",
    "file_path = '/home/deepak/dsciProject/new/new_new_song_lyrics.csv'\n",
    "\n",
    "def load_and_explore_dataset(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Total entries: {len(df)}\")\n",
    "        print(\"\\nLanguage Distribution:\")\n",
    "        print(df['language'].value_counts())\n",
    "        print(\"\\nGenre Distribution:\")\n",
    "        print(df['tag'].value_counts().head())\n",
    "        df_english = df[df['language'] == 'en'].copy()\n",
    "        print(f\"\\nEnglish lyrics count: {len(df_english)}\")\n",
    "        return df_english\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "df_english = load_and_explore_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean Lyrics\n",
    "def clean_lyrics(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove Stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    return ' '.join([word for word in word_tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Preprocess Dataset\n",
    "def preprocess_lyrics_dataset(df):\n",
    "    df['cleaned_lyrics'] = df['lyrics'].apply(clean_lyrics)\n",
    "    df['processed_lyrics'] = df['cleaned_lyrics'].apply(remove_stopwords)\n",
    "    return df\n",
    "\n",
    "if df_english is not None:\n",
    "    df_processed = preprocess_lyrics_dataset(df_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Sentiment Analysis\n",
    "def analyze_lyrics_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    sentiment = 'Positive' if polarity > 0.05 else 'Negative' if polarity < -0.05 else 'Neutral'\n",
    "    return {'sentiment': sentiment, 'polarity': polarity, 'subjectivity': subjectivity}\n",
    "\n",
    "df_processed['sentiment_analysis'] = df_processed['processed_lyrics'].apply(analyze_lyrics_sentiment)\n",
    "df_processed['sentiment'] = df_processed['sentiment_analysis'].apply(lambda x: x['sentiment'])\n",
    "df_processed['polarity'] = df_processed['sentiment_analysis'].apply(lambda x: x['polarity'])\n",
    "df_processed['subjectivity'] = df_processed['sentiment_analysis'].apply(lambda x: x['subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualization\n",
    "def visualize_sentiment_distribution(df):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df['sentiment'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title('Sentiment Distribution')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    df.groupby('tag')['sentiment'].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True)\n",
    "    plt.title('Sentiment by Genre')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_sentiment_distribution(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Processed Data\n",
    "df_processed.to_csv('processed_genius_lyrics_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
